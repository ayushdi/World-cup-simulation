{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import urllib\n",
    "import time\n",
    "import http.cookiejar as cookiejar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import bs4 as bs\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "from scipy import stats\n",
    "\n",
    "style.use('seaborn-deep')\n",
    "\n",
    "import pickle\n",
    "\n",
    "from datalab_beta import *\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this post, we will:\n",
    "\n",
    "- Create a crawler and pull team stats data from the web\n",
    "- Pre-process, explore and visualize that data\n",
    "- Download another type of data, with match results\n",
    "- Join those two datasets and build one model to guess match results\n",
    "- Create a simple Monte Carlo Simulation and get winner odds for the 2018 World Cup - Knockout Stage\n",
    "\n",
    "Some libraries we're going to use:\n",
    "\n",
    "- Pandas\n",
    "- Numpy\n",
    "- Sklearn\n",
    "\n",
    "The World Cup is reaching a new stage and few were those who could anticipate what the spooky group stage unrolled.\n",
    "Now it's time for a much more thrilling phase, where the greatest of the world will face each other. The goal of this post is, using the power of data science, try to uncover some of the stats those games will present.\n",
    "\n",
    "The idea here is to make a machine learning algorithm to predict the winner of a single match, and from there, build a \n",
    "monte carlo simulation that could infer the odds of each knockout game winner, and subsequently, the probability for the world's champion.\n",
    "\n",
    "Be aware that this model is made for education purposes only, and should not be trusted for any kind of betting, even because the number of variables in a game are so huge you could not predict its result without a reasonable uncertainty amount.\n",
    "\n",
    "Most of the game simulations tend to use an overall number that represents a team's performance. Here we are trying a \n",
    "different aproach, using not only the overall, but 3 other values (Attack, Defense, Midside) altogether in a more sofisticated manner, to avoid simply converging all features to a single factor that dictates the team's strenght.\n",
    "\n",
    "This algorithm will be built on top of sklearn library, using Pandas as the library to manipulate data.\n",
    "\n",
    "So, the first step to obtain that data is to make a little crawler and get the information from fifaindex, a great source to pull international team stats back from 2005. I must admit the crawler ended up a bit lazy and it might take in some duplicates to our dataset. No concerns, though, since we can just drop those dupes with pandas later on (I'll also provide a link for downloading raw and processed datasets).\n",
    "\n",
    "I won't get into the very details of the way this scrapper was built, but the code will be left below if you'd like to check it out. In case you're curious about it, don't hesitate on reaching me out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day: 1\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 2\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 3\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 4\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 5\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 6\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 7\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 8\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 9\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 10\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 11\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 12\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 13\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 14\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 15\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 16\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 17\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 18\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 19\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 20\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 21\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 22\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 23\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 24\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 25\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 26\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 27\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 28\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 29\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 30\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 31\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 32\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 33\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 34\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 35\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 36\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 37\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 38\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 39\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 40\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 41\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 42\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 43\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 44\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 45\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 46\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 47\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 48\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 49\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 50\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 51\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 52\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 53\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 54\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 55\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 56\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 57\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 58\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 59\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 60\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 61\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 62\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 63\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 64\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 65\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 66\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 67\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 68\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 69\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 70\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 71\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 72\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 73\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 74\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 75\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 76\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 77\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 78\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 79\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 80\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 81\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 82\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 83\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 84\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 85\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 86\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 87\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 88\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 89\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 90\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 91\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 92\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 93\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 94\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 95\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 96\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 97\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 98\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 99\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 100\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 101\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 102\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 103\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 104\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 105\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 106\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 107\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 108\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 109\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 110\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 111\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 112\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 113\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 114\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 115\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 116\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 117\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 118\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 119\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 120\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 121\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 122\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 123\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 124\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 125\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 126\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 127\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 128\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 129\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 130\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 131\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 132\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 133\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 134\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 135\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 136\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 137\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 138\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 139\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 140\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 141\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 142\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 143\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 144\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 145\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 146\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 147\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 148\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 149\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 150\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 151\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 152\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 153\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 154\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 155\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 156\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 157\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 158\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 159\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 160\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 161\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 162\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 163\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 164\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 165\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 166\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 167\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 168\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 169\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 170\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 171\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 172\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 173\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 174\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 175\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 176\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 177\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 178\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 179\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 180\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 181\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 182\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 183\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 184\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 185\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 186\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 187\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 188\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 189\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 190\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 191\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 192\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 193\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 194\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 195\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 196\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 197\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 198\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 199\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 200\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 201\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 202\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 203\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 204\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 205\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 206\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 207\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 208\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 209\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 210\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 211\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 212\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 213\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 214\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 215\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 216\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 217\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 218\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 219\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 220\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 221\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 222\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 223\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 224\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 225\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 226\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 227\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 228\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 229\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 230\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 231\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 232\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 233\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 234\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 235\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 236\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 237\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 238\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 239\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 240\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 241\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 242\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 243\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 244\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 245\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 246\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 247\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 248\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 249\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 250\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 251\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 252\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 253\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 254\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 255\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 256\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 257\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 258\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n",
      "Day: 259\n",
      "1\n",
      "Could not create soup.\n",
      "Could not create soup.\n",
      "Page found.\n"
     ]
    }
   ],
   "source": [
    "web_address = 'https://www.fifaindex.com/teams/fifa18/'\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for day in range(1,260,1):\n",
    "    for pag in range(1,30):\n",
    "    \n",
    "        source_address = web_address + '05_' + str(day) + '/' + str(pag) + '/' + '?type=1'\n",
    "        print('Day:', str(day))\n",
    "        print(pag)\n",
    "\n",
    "        try:\n",
    "            soup = get_soup(source_address)\n",
    "            result_list =  soup.find('div', {'id': 'no-more-tables'})\n",
    "        except:\n",
    "            print('Page found.')\n",
    "            break\n",
    "\n",
    "        date = str(soup.find('ol', {'class': 'breadcrumb'}))\n",
    "\n",
    "        if df.empty:\n",
    "            df = pd.read_html(str(result_list))[0]\n",
    "            df['date'] = date\n",
    "        else:\n",
    "            temp_df = pd.read_html(str(result_list))[0]\n",
    "            temp_df['date'] = date\n",
    "            df = df.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Well, it seems that columns came out of order, and 'date' column looks really ugly, let's fix it to know what's \n",
    "going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.columns = ['mid', 'ovr', 'att', 'def', 'league', '1', '2', '3', 'name', 'date']\n",
    "df = df[['date', 'name', 'att', 'def', 'mid', 'ovr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(df.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let's fix those dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.iloc[0].date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def split_date(s):\n",
    "    date = s.split('href=\"/teams/')[-1].split('>')[1].split('<')[0].split(',')[1]\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-daae3ecb9483>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\user\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3081\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3083\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'date'"
     ]
    }
   ],
   "source": [
    "df['date'] = df.date.apply(split_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For simplicity sake, I'm going to average the performance of each team by year, so that we have few datapoints to handle. Feel free to keep the months and days and make a much more accurate model if you'd like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df['date'] = df.date.apply(text_norm)\n",
    "df['name'] = df.name.apply(text_norm)\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.drop_duplicates()\n",
    "to_pickle(df, 'team_stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = read_pickle('team_stats.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>att</th>\n",
       "      <th>def</th>\n",
       "      <th>mid</th>\n",
       "      <th>ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004</td>\n",
       "      <td>france</td>\n",
       "      <td>94</td>\n",
       "      <td>84</td>\n",
       "      <td>89</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004</td>\n",
       "      <td>brazil</td>\n",
       "      <td>92</td>\n",
       "      <td>87</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004</td>\n",
       "      <td>spain</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>england</td>\n",
       "      <td>89</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>italy</td>\n",
       "      <td>92</td>\n",
       "      <td>86</td>\n",
       "      <td>83</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date     name  att  def  mid  ovr\n",
       "0  2004   france   94   84   89   88\n",
       "1  2004   brazil   92   87   88   88\n",
       "2  2004    spain   90   86   88   88\n",
       "3  2004  england   89   88   88   88\n",
       "4  2004    italy   92   86   83   87"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = df.groupby(['name', 'date']).mean()\n",
    "df = df.reset_index()\n",
    "df.index = pd.DatetimeIndex(df.date).year\n",
    "df = df.drop(labels='date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>att</th>\n",
       "      <th>def</th>\n",
       "      <th>mid</th>\n",
       "      <th>ovr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>argentina</td>\n",
       "      <td>86.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>argentina</td>\n",
       "      <td>87.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>argentina</td>\n",
       "      <td>87.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>argentina</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>argentina</td>\n",
       "      <td>87.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name   att   def   mid   ovr\n",
       "date                                   \n",
       "2004  argentina  86.0  87.0  85.0  85.0\n",
       "2005  argentina  87.0  85.0  81.0  83.0\n",
       "2006  argentina  87.0  78.0  80.0  83.0\n",
       "2007  argentina  85.0  80.0  80.0  83.0\n",
       "2008  argentina  87.0  82.0  84.0  84.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "year_dic = {}\n",
    "\n",
    "for year in df.date.unique():\n",
    "    df_year = df[df.date == year]\n",
    "    df_year = df_year[df_year.ovr == df_year.ovr.max()]\n",
    "    year_dic[year] = [max(df_year.ovr.tolist()), df_year.name.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_ovrs = []\n",
    "for year in df.date.unique():\n",
    "    df_year = df[df.date == year]\n",
    "    mean_ovrs.append(df_year.ovr.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "years = list(year_dic.keys())\n",
    "max_ovrs = [i[0] for i in list(year_dic.values())]\n",
    "teams = [i[1] for i in list(year_dic.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "teams_str = []\n",
    "for t in teams:\n",
    "    try:\n",
    "        teams_str.append(str(', '.join(t)))\n",
    "    except:\n",
    "        teams_str.append(t)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's check the best performing teams for each date in a bar chart and see how they changed during the years. You can hover over each bar to check team's name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>att</th>\n",
       "      <th>def</th>\n",
       "      <th>mid</th>\n",
       "      <th>ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004</td>\n",
       "      <td>argentina</td>\n",
       "      <td>86.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005</td>\n",
       "      <td>argentina</td>\n",
       "      <td>87.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006</td>\n",
       "      <td>argentina</td>\n",
       "      <td>87.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007</td>\n",
       "      <td>argentina</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>argentina</td>\n",
       "      <td>87.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date       name   att   def   mid   ovr\n",
       "0  2004  argentina  86.0  87.0  85.0  85.0\n",
       "1  2005  argentina  87.0  85.0  81.0  83.0\n",
       "2  2006  argentina  87.0  78.0  80.0  83.0\n",
       "3  2007  argentina  85.0  80.0  80.0  83.0\n",
       "4  2008  argentina  87.0  82.0  84.0  84.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~rodrigonader/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "plotly.tools.set_credentials_file(username='rodrigonader', api_key='MFs1Eh244N8I7ePAG3Va')\n",
    "\n",
    "trace1= go.Bar(\n",
    "            x=years,\n",
    "            y=max_ovrs,\n",
    "            text=teams_str,\n",
    "            name = 'Max Performance',\n",
    "            marker=dict(\n",
    "            color='rgb(103,113,242)')\n",
    "    )\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "    x = years,\n",
    "    y = mean_ovrs,\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Mean Performance',\n",
    "    marker = dict(\n",
    "        size = 12,\n",
    "        color = 'rgba(300, 300, 300, .9)',\n",
    "        line = dict(\n",
    "            width = 2)\n",
    "        )\n",
    ")\n",
    "\n",
    "\n",
    "data = [trace1, trace2]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Team performance by year',\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "py.iplot(fig, filename='text-hover-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~rodrigonader/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=[]\n",
    "for year in years:\n",
    "    \n",
    "    values = df.ovr[df.date==year].tolist()\n",
    "    \n",
    "\n",
    "    trace1 = go.Scatter(\n",
    "                x=[year] * len(values),\n",
    "                y=values,\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                color='rgb(150,150,150)')\n",
    "        )\n",
    "    \n",
    "    \n",
    "    data.append(trace1)\n",
    "\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "\n",
    "py.iplot(fig, filename='text-hover-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# mais vizualizaes aqui"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's now open the csv file containing match result information of international teams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results = pd.read_csv('match_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>tournament</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1872-11-30</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>England</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1873-03-08</td>\n",
       "      <td>England</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>London</td>\n",
       "      <td>England</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1874-03-07</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>England</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1875-03-06</td>\n",
       "      <td>England</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>London</td>\n",
       "      <td>England</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1876-03-04</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>England</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date home_team away_team  home_score  away_score tournament     city  \\\n",
       "0  1872-11-30  Scotland   England           0           0   Friendly  Glasgow   \n",
       "1  1873-03-08   England  Scotland           4           2   Friendly   London   \n",
       "2  1874-03-07  Scotland   England           2           1   Friendly  Glasgow   \n",
       "3  1875-03-06   England  Scotland           2           2   Friendly   London   \n",
       "4  1876-03-04  Scotland   England           3           0   Friendly  Glasgow   \n",
       "\n",
       "    country  neutral  \n",
       "0  Scotland    False  \n",
       "1   England    False  \n",
       "2  Scotland    False  \n",
       "3   England    False  \n",
       "4  Scotland    False  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>scotland</td>\n",
       "      <td>england</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>england</td>\n",
       "      <td>scotland</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>scotland</td>\n",
       "      <td>england</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>england</td>\n",
       "      <td>scotland</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>scotland</td>\n",
       "      <td>england</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     home_team away_team  home_score  away_score  neutral\n",
       "date                                                     \n",
       "1872  scotland   england           0           0    False\n",
       "1873   england  scotland           4           2    False\n",
       "1874  scotland   england           2           1    False\n",
       "1875   england  scotland           2           2    False\n",
       "1876  scotland   england           3           0    False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = results.drop(['city', 'tournament', 'country'], axis=1)\n",
    "results.home_team = results.home_team.apply(text_norm)\n",
    "results.away_team = results.away_team.apply(text_norm)\n",
    "results.index = pd.DatetimeIndex(results.date).year\n",
    "results = results.drop('date', 1)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "3 steps are going to be important to start cleaning this data. First, as we only have performance data for 2004 on, \n",
    "we should get rid of all those other years. Second, we shouldn't be working with teams that aren't in the df \n",
    "dataframe (our main dataframe), since we don't have stats for them. Finally we have to work around this home-away \n",
    "team situation, since for world cup prediction we are going to consider all teams being away. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results = results.loc[2004:2017]\n",
    "results.tail()\n",
    "\n",
    "df_teams = list(df.name.unique())\n",
    "results = results.reset_index()\n",
    "\n",
    "for index, row in results.iterrows():\n",
    "    if row.home_team not in df_teams:\n",
    "        results.loc[index, 'home_team'] = None\n",
    "    if row.away_team not in df_teams:\n",
    "        results.loc[index, 'away_team'] = None\n",
    "        \n",
    "results = results.dropna()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For the last problem we are going to consider all world cup games as neutral.\n",
    "Let's now input the teams stats into the results dataframe, we are going to do this by creating 8 new columns in \n",
    "the results dataframe, representing 4 skills for each team. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\__main__.py:15: UserWarning:\n",
      "\n",
      "Boolean Series key will be reindexed to match DataFrame index.\n",
      "\n",
      "C:\\Users\\user\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\__main__.py:16: UserWarning:\n",
      "\n",
      "Boolean Series key will be reindexed to match DataFrame index.\n",
      "\n",
      "C:\\Users\\user\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\__main__.py:17: UserWarning:\n",
      "\n",
      "Boolean Series key will be reindexed to match DataFrame index.\n",
      "\n",
      "C:\\Users\\user\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\__main__.py:18: UserWarning:\n",
      "\n",
      "Boolean Series key will be reindexed to match DataFrame index.\n",
      "\n",
      "C:\\Users\\user\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\__main__.py:19: UserWarning:\n",
      "\n",
      "Boolean Series key will be reindexed to match DataFrame index.\n",
      "\n",
      "C:\\Users\\user\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\__main__.py:20: UserWarning:\n",
      "\n",
      "Boolean Series key will be reindexed to match DataFrame index.\n",
      "\n",
      "C:\\Users\\user\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\__main__.py:21: UserWarning:\n",
      "\n",
      "Boolean Series key will be reindexed to match DataFrame index.\n",
      "\n",
      "C:\\Users\\user\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\__main__.py:22: UserWarning:\n",
      "\n",
      "Boolean Series key will be reindexed to match DataFrame index.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results['att1'] = np.nan\n",
    "results['def1'] = np.nan\n",
    "results['mid1'] = np.nan\n",
    "results['ovr1'] = np.nan\n",
    "results['att2'] = np.nan\n",
    "results['def2'] = np.nan\n",
    "results['mid2'] = np.nan\n",
    "results['ovr2'] = np.nan\n",
    "\n",
    "for index, row in results.iterrows():\n",
    "    date = row.date\n",
    "    team1 = row.home_team\n",
    "    team2 = row.away_team\n",
    "    try:\n",
    "        results.loc[index, 'att1'] = df[df.date == date][df.name == team1]['att'].iloc[0]\n",
    "        results.loc[index, 'def1'] = df[df.date == date][df.name == team1]['def'].iloc[0]\n",
    "        results.loc[index, 'mid1'] = df[df.date == date][df.name == team1]['mid'].iloc[0]\n",
    "        results.loc[index, 'ovr1'] = df[df.date == date][df.name == team1]['ovr'].iloc[0]\n",
    "        results.loc[index, 'att2'] = df[df.date == date][df.name == team2]['att'].iloc[0]\n",
    "        results.loc[index, 'def2'] = df[df.date == date][df.name == team2]['def'].iloc[0]\n",
    "        results.loc[index, 'mid2'] = df[df.date == date][df.name == team2]['mid'].iloc[0]\n",
    "        results.loc[index, 'ovr2'] = df[df.date == date][df.name == team2]['ovr'].iloc[0]\n",
    "        \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results = results.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>neutral</th>\n",
       "      <th>att1</th>\n",
       "      <th>def1</th>\n",
       "      <th>mid1</th>\n",
       "      <th>ovr1</th>\n",
       "      <th>att2</th>\n",
       "      <th>def2</th>\n",
       "      <th>mid2</th>\n",
       "      <th>ovr2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2004</td>\n",
       "      <td>sweden</td>\n",
       "      <td>norway</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>83.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2004</td>\n",
       "      <td>cameroon</td>\n",
       "      <td>nigeria</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>72.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2004</td>\n",
       "      <td>tunisia</td>\n",
       "      <td>nigeria</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>69.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2004</td>\n",
       "      <td>belgium</td>\n",
       "      <td>france</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>74.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2004</td>\n",
       "      <td>croatia</td>\n",
       "      <td>germany</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    date home_team away_team  home_score  away_score  neutral  att1  def1  \\\n",
       "31  2004    sweden    norway           0           3     True  83.0  75.0   \n",
       "73  2004  cameroon   nigeria           1           2     True  72.0  75.0   \n",
       "79  2004   tunisia   nigeria           1           1    False  69.0  63.0   \n",
       "93  2004   belgium    france           0           2    False  74.0  71.0   \n",
       "95  2004   croatia   germany           1           2    False  74.0  80.0   \n",
       "\n",
       "    mid1  ovr1  att2  def2  mid2  ovr2  \n",
       "31  76.0  77.0  76.0  77.0  73.0  75.0  \n",
       "73  78.0  75.0  77.0  74.0  71.0  73.0  \n",
       "79  68.0  64.0  77.0  74.0  71.0  73.0  \n",
       "93  75.0  73.0  94.0  84.0  89.0  88.0  \n",
       "95  75.0  76.0  81.0  85.0  85.0  85.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Finally we need to compact the number of goals of each team in a single feature, which is the target to be predicted.\n",
    "Let's just subtract home_score from away_score, so that we have one score representing which team wins (if score > 0,\n",
    "that means home_team won, otherwise away_team won). Notice that I'm using the terms home and away simply because this\n",
    "is the way this dataset has come, but this will not influence in our analysis, as we'll work only with neutral games in the regression. Anyway the terms home and away are going to stick for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results['score'] = results.home_score - results.away_score\n",
    "# results = results.drop(['home_score', 'away_score', 'home_team', 'away_team'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\user\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\__main__.py:3: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "C:\\Users\\user\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\__main__.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results['winner'] = None\n",
    "results['winner'][results.score > 0] = 1\n",
    "results['winner'][results.score < 0] = -1\n",
    "results['winner'][results.score == 0] = 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Just to simplify the problem a little more, I'm going to help the model extracting the differences between abilities, \n",
    "instead of providing the performance itself, we're going to provide the performance contrast between matching teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results['att'] = results['att1'] - results['att2']\n",
    "results['def'] = results['def1'] - results['def2']\n",
    "results['mid'] = results['mid1'] - results['mid2']\n",
    "results['ovr'] = results['ovr1'] - results['ovr2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results = results[results.winner != 0]\n",
    "\n",
    "to_drop = results[results.winner == 1].sample(247)\n",
    "results = results.drop(labels=to_drop.index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>neutral</th>\n",
       "      <th>att1</th>\n",
       "      <th>def1</th>\n",
       "      <th>mid1</th>\n",
       "      <th>ovr1</th>\n",
       "      <th>att2</th>\n",
       "      <th>def2</th>\n",
       "      <th>mid2</th>\n",
       "      <th>ovr2</th>\n",
       "      <th>score</th>\n",
       "      <th>att</th>\n",
       "      <th>def</th>\n",
       "      <th>mid</th>\n",
       "      <th>ovr</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2004</td>\n",
       "      <td>sweden</td>\n",
       "      <td>norway</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>83.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2004</td>\n",
       "      <td>cameroon</td>\n",
       "      <td>nigeria</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>72.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2004</td>\n",
       "      <td>belgium</td>\n",
       "      <td>france</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>74.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2004</td>\n",
       "      <td>croatia</td>\n",
       "      <td>germany</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2004</td>\n",
       "      <td>greece</td>\n",
       "      <td>bulgaria</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>75.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    date home_team away_team  home_score  away_score  neutral  att1  def1  \\\n",
       "31  2004    sweden    norway           0           3     True  83.0  75.0   \n",
       "73  2004  cameroon   nigeria           1           2     True  72.0  75.0   \n",
       "93  2004   belgium    france           0           2    False  74.0  71.0   \n",
       "95  2004   croatia   germany           1           2    False  74.0  80.0   \n",
       "98  2004    greece  bulgaria           2           0    False  75.0  81.0   \n",
       "\n",
       "    mid1  ovr1  att2  def2  mid2  ovr2  score   att   def   mid   ovr winner  \n",
       "31  76.0  77.0  76.0  77.0  73.0  75.0     -3   7.0  -2.0   3.0   2.0     -1  \n",
       "73  78.0  75.0  77.0  74.0  71.0  73.0     -1  -5.0   1.0   7.0   2.0     -1  \n",
       "93  75.0  73.0  94.0  84.0  89.0  88.0     -2 -20.0 -13.0 -14.0 -15.0     -1  \n",
       "95  75.0  76.0  81.0  85.0  85.0  85.0     -1  -7.0  -5.0 -10.0  -9.0     -1  \n",
       "98  78.0  79.0  81.0  69.0  74.0  73.0      2  -6.0  12.0   4.0   6.0      1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~rodrigonader/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace = go.Scatter(\n",
    "    x = results.ovr1,\n",
    "    y = results.score,\n",
    "    mode = 'markers',\n",
    "    name = 'Mean Performance',\n",
    "    marker = dict(\n",
    "        size = 12,\n",
    "        color = 'rgba(300, 300, 300, .9)',\n",
    "        line = dict(\n",
    "            width = 2)\n",
    "        )\n",
    ")\n",
    "\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "\n",
    "py.iplot(fig, filename='text-hover-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~rodrigonader/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace = go.Scatter3d(\n",
    "    x = results.att,\n",
    "    y = results.def1,\n",
    "    z = results.mid1,\n",
    "    mode = 'markers',\n",
    "    name = 'Mean Performance',\n",
    "    marker = dict(\n",
    "        size = np.power(results.score.tolist(), 2),\n",
    "        color = 'rgba(100, 150, 300, .9)',\n",
    "        line = dict(\n",
    "            width = 1)\n",
    "        )\n",
    ")\n",
    "\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "layout = {\n",
    "  \"margin\": {\n",
    "    \"r\": 10, \n",
    "    \"t\": 25, \n",
    "    \"b\": 40, \n",
    "    \"l\": 60\n",
    "  }, \n",
    "  \"paper_bgcolor\": \"rgb(243, 243, 243)\", \n",
    "  \"plot_bgcolor\": \"rgb(243, 243, 243)\", \n",
    "  \"scene\": {\n",
    "    \"xaxis\": {\n",
    "      \"gridcolor\": \"rgb(255, 255, 255)\", \n",
    "      \"gridwidth\": 2, \n",
    "      \"ticklen\": 5, \n",
    "      \"title\": \"Attack\", \n",
    "      \"type\": \"log\", \n",
    "      \"zerolinewidth\": 1\n",
    "    }, \n",
    "    \"yaxis\": {\n",
    "      \"gridcolor\": \"rgb(255, 255, 255)\", \n",
    "      \"ticklen\": 5, \n",
    "      \"title\": \"Defense\", \n",
    "      \"zerolinewidth\": 1\n",
    "    }, \n",
    "    \"zaxis\": {\n",
    "      \"gridcolor\": \"rgb(255, 255, 255)\", \n",
    "      \"ticklen\": 5, \n",
    "      \"title\": \"Midside\", \n",
    "      \"type\": \"log\", \n",
    "      \"zerolinewidth\": 1\n",
    "    }\n",
    "  }, \n",
    "  \"title\": \"Teams Performance 3D\", \n",
    "  \"xaxis\": {\"domain\": [0, 1]}, \n",
    "  \"yaxis\": {\"domain\": [0, 1]}\n",
    "}\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "# fig = go.Figure(data=data)\n",
    "\n",
    "py.iplot(fig, filename='text-hover-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# to_pickle(results, 'results_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def prepare(data, target_col='price_area'):\n",
    "\n",
    "\tfeatures = data.drop(target_col, 1)\n",
    "\ttarget = data[target_col]\n",
    "\tx = to_array(features)\n",
    "\n",
    "\ty = to_array(target)\n",
    "\n",
    "\treturn x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "results.winner = results.winner.apply(to_float)\n",
    "\n",
    "results.replace(np.inf, np.nan)\n",
    "results = results.dropna()\n",
    "\n",
    "results = results.sample(frac=1)\n",
    "\n",
    "data = results.drop(['date', 'score'], 1)\n",
    "data = results[['def', 'ovr', 'att', 'mid', 'winner']]\n",
    "train, test = train_test_split(data, 0.2)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "x_train, y_train = prepare(train, target_col='winner')\n",
    "x_test, y_test = prepare(test, target_col='winner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "This reveals that, althought it may seem that the overall is the consolidation of the other 3 attributes, this is not,\n",
    "actually true, since, when we remove those other features, the regressor performs less accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73711340206185572"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "accuracy_score(y_test, lr.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66494845360824739"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "accuracy_score(y_test, rf.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73195876288659789"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(kernel='linear')\n",
    "svc.fit(x_train, y_train)\n",
    "\n",
    "accuracy_score(y_test, svc.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test['prediction'] = svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>def</th>\n",
       "      <th>ovr</th>\n",
       "      <th>att</th>\n",
       "      <th>mid</th>\n",
       "      <th>winner</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8.52381</td>\n",
       "      <td>-6.047619</td>\n",
       "      <td>-1.698413</td>\n",
       "      <td>-4.777778</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.50000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.22500</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       def       ovr       att       mid  winner  prediction\n",
       "0 -8.52381 -6.047619 -1.698413 -4.777778    -1.0        -1.0\n",
       "1  3.00000  0.000000 -2.000000 -1.000000    -1.0        -1.0\n",
       "2 -2.50000 -0.500000  2.500000  0.000000    -1.0        -1.0\n",
       "3  1.00000  4.000000  7.000000  5.000000    -1.0         1.0\n",
       "4 -1.22500  0.475000 -1.250000 -0.175000     1.0        -1.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's check our model performance for each class independently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "first_score = accuracy_score(test.winner[test.winner > 0].values, test.prediction[test.winner > 0].values)\n",
    "second_score = accuracy_score(test.winner[test.winner < 0].values, test.prediction[test.winner < 0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~rodrigonader/4.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace1= go.Bar(\n",
    "            x=['First Team Wins', 'Second Team Wins'],\n",
    "            y=[first_score, second_score],\n",
    "            name = 'Model Scores',\n",
    "            marker=dict(\n",
    "            color='rgb(50,300,160)'\n",
    "            )\n",
    "    \n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = [trace1]\n",
    "\n",
    "\n",
    "# fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "py.iplot(data, filename='Model-Scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No tables found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-b59fb1c9a780>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mwc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mtemp_wc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mtemp_wc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mwc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_wc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, tupleize_cols, thousands, encoding, decimal, converters, na_values, keep_default_na)\u001b[0m\n\u001b[0;32m    904\u001b[0m                   \u001b[0mthousands\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthousands\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m                   \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconverters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 906\u001b[1;33m                   keep_default_na=keep_default_na)\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\user\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, **kwargs)\u001b[0m\n\u001b[0;32m    741\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 743\u001b[1;33m         \u001b[0mraise_with_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretained\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    744\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\pandas\\compat\\__init__.py\u001b[0m in \u001b[0;36mraise_with_traceback\u001b[1;34m(exc, traceback)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mEllipsis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m     \u001b[1;31m# this version of raise is a syntax error in Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No tables found"
     ]
    }
   ],
   "source": [
    "web_address = 'https://www.fifaindex.com/teams/fifa18wc_262/'\n",
    "\n",
    "wc = pd.DataFrame()\n",
    "\n",
    "for pag in range(1,30):\n",
    "\n",
    "    source_address = web_address + str(pag) + '/' + '?type=1'\n",
    "    print(pag)\n",
    "\n",
    "    try:\n",
    "        soup = get_soup(source_address)\n",
    "        result_list =  soup.find('div', {'id': 'no-more-tables'})\n",
    "    except:\n",
    "        print('Page not found.')\n",
    "        break\n",
    "\n",
    "    if df.empty:\n",
    "        wc = pd.read_html(str(result_list))[0]\n",
    "        wc['date'] = date\n",
    "    else:\n",
    "        temp_wc = pd.read_html(str(result_list))[0]\n",
    "        temp_wc['date'] = date\n",
    "        wc = wc.append(temp_wc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We have a little more accuracy on the first team, that may be related to the fact that in the original dataset, this team is the home team, and it could affect the behavior of the model, but apart from that, it could be simply random as well, so let's move on.\n",
    "\n",
    "That's ok. We have a predictor that can guess with 70% accuracy which team is going to win. Enough for building a \n",
    "simulation. Shall we?\n",
    "\n",
    "First thing we need is performance data for world cup teams that were classified in groups stage. We'll build a scraper similar to the one we built for the other years, but now using 2018 World Cup performance data\n",
    "from fifaindex. \n",
    "\n",
    "Unfortunately it seems that this data does not differ much from 2018 (non world cup) data. Since Germany still ocupies\n",
    "the second place in the ranking, while in reality it's already out of the competition. Anyway we'll stick to this source to gather our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "wc.columns = ['0', 'name', '1', 'att', 'mid', 'def', 'ovr', '2', '3', '4']\n",
    "wc = wc[['name', 'att', 'def', 'mid', 'ovr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "wc.name = wc.name.apply(text_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>att</th>\n",
       "      <th>def</th>\n",
       "      <th>mid</th>\n",
       "      <th>ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brazil</td>\n",
       "      <td>87</td>\n",
       "      <td>84</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>germany</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>france</td>\n",
       "      <td>86</td>\n",
       "      <td>81</td>\n",
       "      <td>84</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spain</td>\n",
       "      <td>84</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>portugal</td>\n",
       "      <td>88</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  att  def  mid  ovr\n",
       "0    brazil   87   84   86   86\n",
       "1   germany   85   85   85   86\n",
       "2    france   86   81   84   85\n",
       "3     spain   84   85   86   85\n",
       "4  portugal   88   82   83   84"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc = read_pickle('world_cup_teams.pickle')\n",
    "wc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def match(wc, team1, team2, model):\n",
    "    \n",
    "    match = pd.DataFrame(columns=['att1','def1','mid1','ovr1','att2','def2','mid2','ovr2'], index=[0])\n",
    "    \n",
    "    match['att1'] = wc[wc.name == team1]['att'].iloc[0]\n",
    "    match['def1'] = wc[wc.name == team1]['def'].iloc[0]\n",
    "    match['mid1'] = wc[wc.name == team1]['mid'].iloc[0]\n",
    "    match['ovr1'] = wc[wc.name == team1]['ovr'].iloc[0]\n",
    "\n",
    "    match['att2'] = wc[wc.name == team2]['att'].iloc[0]\n",
    "    match['def2'] = wc[wc.name == team2]['def'].iloc[0]\n",
    "    match['mid2'] = wc[wc.name == team2]['mid'].iloc[0]\n",
    "    match['ovr2'] = wc[wc.name == team2]['ovr'].iloc[0]\n",
    "    \n",
    "    match['att'] = match['att1'] - match['att2']\n",
    "    match['def'] = match['def1'] - match['def2']\n",
    "    match['mid'] = match['mid1'] - match['mid2']\n",
    "    match['ovr'] = match['ovr1'] - match['ovr2']\n",
    "    \n",
    "    match = match[['att', 'def', 'mid', 'ovr']]\n",
    "    \n",
    "    match_array = match.values\n",
    "    \n",
    "    prediction = model.predict(match_array)\n",
    "    \n",
    "    winner = None\n",
    "    \n",
    "    if prediction == 1:\n",
    "        winner = team1\n",
    "    elif prediction == -1:\n",
    "        winner = team2\n",
    "    \n",
    "    return winner\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spain'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match(wc, 'brazil', 'spain', svc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Oh I see. Didn't expect that sad outcome for us! But there's a major problem here, team performance vary a lot, and the firt phase of this cup is proof. So let's add some randomness to it, so that results will not be always the same every time we simulate a game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def match(wc, team1, team2, model, random_scale=5):\n",
    "    \n",
    "    match = pd.DataFrame(columns=['att1','def1','mid1','ovr1','att2','def2','mid2','ovr2'], index=[0])\n",
    "    \n",
    "    att1 = wc[wc.name == team1]['att'].iloc[0]\n",
    "    def1 = wc[wc.name == team1]['def'].iloc[0]\n",
    "    mid1 = wc[wc.name == team1]['mid'].iloc[0]\n",
    "    ovr1 = wc[wc.name == team1]['ovr'].iloc[0]\n",
    "\n",
    "    att2 = wc[wc.name == team2]['att'].iloc[0]\n",
    "    def2 = wc[wc.name == team2]['def'].iloc[0]\n",
    "    mid2 = wc[wc.name == team2]['mid'].iloc[0]\n",
    "    ovr2 = wc[wc.name == team2]['ovr'].iloc[0]\n",
    "    \n",
    "    match['att1'] = np.random.normal(att1, scale=random_scale)\n",
    "    match['def1'] = np.random.normal(def1, scale=random_scale)\n",
    "    match['mid1'] = np.random.normal(mid1, scale=random_scale)\n",
    "    match['ovr1'] = np.random.normal(ovr1, scale=random_scale)\n",
    "\n",
    "    match['att2'] = np.random.normal(att2, scale=random_scale)\n",
    "    match['def2'] = np.random.normal(def2, scale=random_scale)\n",
    "    match['mid2'] = np.random.normal(mid2, scale=random_scale)\n",
    "    match['ovr2'] = np.random.normal(ovr2, scale=random_scale)\n",
    "    \n",
    "    match['att'] = match['att1'] - match['att2']\n",
    "    match['def'] = match['def1'] - match['def2']\n",
    "    match['mid'] = match['mid1'] - match['mid2']\n",
    "    match['ovr'] = match['ovr1'] - match['ovr2']\n",
    "    \n",
    "    match = match[['att', 'def', 'mid', 'ovr']]\n",
    "    \n",
    "    match_array = match.values\n",
    "    \n",
    "    prediction = model.predict(match_array)\n",
    "    \n",
    "    winner = None\n",
    "    \n",
    "    if prediction == 1:\n",
    "        winner = team1\n",
    "    elif prediction == -1:\n",
    "        winner = team2\n",
    "    \n",
    "    return winner"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here, random_scale will be the factor that determines how much randomness we want to apply to a team's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def simulate_matches(team1, team2, n_matches=10000):\n",
    "    \n",
    "    match_results = []\n",
    "    for i in range(n_matches):\n",
    "        match_results.append(match(wc, team1, team2, svc, random_scale=5))\n",
    "        \n",
    "    team1_proba = match_results.count(team1) / len(match_results) * 100\n",
    "    team2_proba = match_results.count(team2) / len(match_results) * 100\n",
    "    \n",
    "    print(team1, str(round(team1_proba, 2)) + '%')\n",
    "    print(team2, str(round(team2_proba,2)) + '%')\n",
    "    print('-------------------------')\n",
    "    print()\n",
    "    \n",
    "    if team1_proba > team2_proba:\n",
    "        overall_winner = team1\n",
    "    else:\n",
    "        overall_winner = team2\n",
    "    \n",
    "    return {'team1': team1,\n",
    "            'team2': team2,\n",
    "            'team1_proba': team1_proba, \n",
    "            'team2_proba': team2_proba, \n",
    "            'overall_winner': overall_winner,\n",
    "            'match_results': match_results}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "croatia 44.2%\n",
      "denmark 55.8%\n",
      "-------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simulation_test = simulate_matches('croatia', 'denmark', n_matches=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "p_list = []\n",
    "for i in range(len(simulation_test['match_results'])):\n",
    "    denmark = simulation_test['match_results'][:i].count('denmark') / (i+1) * 100\n",
    "    croatia = simulation_test['match_results'][:i].count('croatia') / (i+1) * 100\n",
    "    p_list.append(denmark - croatia)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~rodrigonader/6.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace = go.Scatter(\n",
    "    y = p_list,\n",
    "    name='Teams divergence by number of simulations',\n",
    "    marker= dict(color='rgb(230,90,110)'))\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "py.iplot(data, filename='Divergence')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can see that winner probabilities stabilize around 8k match simulations, so that's the value we're going to use. \n",
    "Let's build the championship tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round of 16:\n",
      "uruguay 46.96%\n",
      "portugal 53.04%\n",
      "-------------------------\n",
      "\n",
      "france 47.8%\n",
      "argentina 52.2%\n",
      "-------------------------\n",
      "\n",
      "brazil 76.88%\n",
      "mexico 23.12%\n",
      "-------------------------\n",
      "\n",
      "belgium 75.01%\n",
      "japan 24.99%\n",
      "-------------------------\n",
      "\n",
      "spain 75.31%\n",
      "russia 24.69%\n",
      "-------------------------\n",
      "\n",
      "croatia 35.06%\n",
      "denmark 64.94%\n",
      "-------------------------\n",
      "\n",
      "sweden 48.39%\n",
      "switzerland 51.61%\n",
      "-------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-f8ba60b3b0e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mko6\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimulate_matches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'croatia'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'denmark'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_matches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'overall_winner'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mko7\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimulate_matches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sweden'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'switzerland'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_matches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'overall_winner'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mko8\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimulate_matches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'colombia'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'england'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_matches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'overall_winner'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-95-5402003a01d9>\u001b[0m in \u001b[0;36msimulate_matches\u001b[1;34m(team1, team2, n_matches)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmatch_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_matches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mmatch_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mteam1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mteam2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mteam1_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mteam1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatch_results\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-94-641796a6ffe3>\u001b[0m in \u001b[0;36mmatch\u001b[1;34m(wc, team1, team2, model, random_scale)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mmatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ovr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ovr1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ovr2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mmatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'att'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'def'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ovr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mmatch_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1956\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1957\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1958\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1959\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2001\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2002\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2003\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2005\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, convert, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   1926\u001b[0m         new_data = self._data.take(indices,\n\u001b[0;32m   1927\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1928\u001b[1;33m                                    convert=True, verify=True)\n\u001b[0m\u001b[0;32m   1929\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[0;32m   4009\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4010\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[1;32m-> 4011\u001b[1;33m                                     axis=axis, allow_dups=True)\n\u001b[0m\u001b[0;32m   4012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4013\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[0;32m   3899\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3900\u001b[0m         \u001b[0mnew_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3901\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_blocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_axes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3903\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slice_take_blocks_ax0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_or_indexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, blocks, axes, do_integrity_check, fastpath)\u001b[0m\n\u001b[0;32m   2797\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2799\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2800\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2801\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmake_empty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\AppData\\Local\\Enthought\\Canopy\\edm\\envs\\User\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_rebuild_blknos_and_blklocs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2886\u001b[0m             \u001b[0mrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2887\u001b[0m             \u001b[0mnew_blknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblkno\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2888\u001b[1;33m             \u001b[0mnew_blklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2890\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnew_blknos\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Round of 16:')\n",
    "\n",
    "ko1 = simulate_matches('uruguay', 'portugal', n_matches=8000)['overall_winner']\n",
    "ko2 = simulate_matches('france', 'argentina', n_matches=8000)['overall_winner']\n",
    "ko3 = simulate_matches('brazil', 'mexico', n_matches=8000)['overall_winner']\n",
    "ko4 = simulate_matches('belgium', 'japan', n_matches=8000)['overall_winner']\n",
    "ko5 = simulate_matches('spain', 'russia', n_matches=8000)['overall_winner']\n",
    "ko6 = simulate_matches('croatia', 'denmark', n_matches=8000)['overall_winner']\n",
    "ko7 = simulate_matches('sweden', 'switzerland', n_matches=8000)['overall_winner']\n",
    "ko8 = simulate_matches('colombia', 'england', n_matches=8000)['overall_winner']\n",
    "\n",
    "print()\n",
    "print('Quarter Finals:')\n",
    "print()\n",
    "\n",
    "quarters1 = simulate_matches(ko1, ko2, n_matches=8000)['overall_winner']\n",
    "quarters2 = simulate_matches(ko3, ko4, n_matches=8000)['overall_winner']\n",
    "quarters3 = simulate_matches(ko5, ko6, n_matches=8000)['overall_winner']\n",
    "quarters4 = simulate_matches(ko7, ko8, n_matches=8000)['overall_winner']\n",
    "\n",
    "print()\n",
    "print('Semi Finals:')\n",
    "print()\n",
    "\n",
    "semifinals1 = simulate_matches(quarters1, quarters2, n_matches=8000)['overall_winner']\n",
    "semifinals2 = simulate_matches(quarters3, quarters4, n_matches=8000)['overall_winner']\n",
    "\n",
    "print()\n",
    "print('Finals:')\n",
    "print()\n",
    "\n",
    "finals = simulate_matches(semifinals1, semifinals2, n_matches=8000)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Considering that our model has an error of 30%, let's calculate the chance of Spain beating all teams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chance of Spain winning: 7.2%\n"
     ]
    }
   ],
   "source": [
    "spain_proba = 0.817 * 0.7 * 0.862 * 0.7 * 0.718 * 0.7 * 0.593 * 0.7 * 100\n",
    "\n",
    "print('Chance of Spain winning:', str(round(spain_proba,2)) + '%')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Well, it seems quite fair.\n",
    "\n",
    "\n",
    "That's it for this article. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next Steps:\n",
    "\n",
    "- Try more complex ML algorithms\n",
    "- Gather more data: national team stats and matches\n",
    "- Go even further and make new model for team evaluation based on player stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
